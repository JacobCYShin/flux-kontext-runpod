#!/usr/bin/env python3
"""
ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© Flux Kontext ìŠ¤í¬ë¦½íŠ¸
ê¸°ì¡´ main.pyì˜ í•µì‹¬ ë¡œì§ì„ ì¬ì‚¬ìš©í•˜ë˜ RunPod ì˜ì¡´ì„±ì„ ì œê±°í•œ ë²„ì „
"""

import os
import sys
import argparse
from pathlib import Path
from PIL import Image
import torch
from diffusers import FluxKontextPipeline
from diffusers.utils import load_image
from nunchaku import NunchakuFluxTransformer2dModel
from nunchaku.utils import get_precision

# utils.pyì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë“¤ import
from utils import (
    LATENT_RGB_FACTORS,
    resize_to_target_area,
    encode_image_to_base64,
    decode_base64_to_image,
)

def load_model():
    """ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    print("ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    try:
        transformer = NunchakuFluxTransformer2dModel.from_pretrained(
            f"mit-han-lab/nunchaku-flux.1-kontext-dev/svdq-{get_precision()}_r32-flux.1-kontext-dev.safetensors"
        )

        pipeline = FluxKontextPipeline.from_pretrained(
            "black-forest-labs/FLUX.1-Kontext-dev", 
            transformer=transformer, 
            torch_dtype=torch.bfloat16
        ).to("cuda")
        
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        return pipeline
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

def create_progress_callback(total_steps):
    """ì§„í–‰ ìƒí™©ì„ ì½˜ì†”ì— ì¶œë ¥í•˜ëŠ” ì½œë°± í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    def on_step_end_callback(pipeline, step: int, timestep: int, callback_kwargs: dict):
        progress = int(((step + 1) / total_steps) * 100)
        
        # 5ë‹¨ê³„ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œ ì§„í–‰ ìƒí™© ì¶œë ¥
        if (step + 1) % 5 == 0 or (step + 1) == total_steps:
            print(f"ğŸ”„ ìƒì„± ì§„í–‰ë¥ : {progress}% ({step + 1}/{total_steps})")
        
        return {"latents": callback_kwargs["latents"]}
    
    return on_step_end_callback

def process_image(image_path, prompt, ratio, output_path="output.png"):
    """ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    print(f"ğŸ“¸ ì…ë ¥ ì´ë¯¸ì§€: {image_path}")
    print(f"ğŸ’¬ í”„ë¡¬í”„íŠ¸: {prompt}")
    print(f"ğŸ“ ë¹„ìœ¨: {ratio}")
    
    # ëª¨ë¸ ë¡œë“œ
    model = load_model()
    if model is None:
        return False
    
    try:
        # ì…ë ¥ ì´ë¯¸ì§€ ì²˜ë¦¬
        if image_path.startswith(("http://", "https://")):
            input_image = load_image(image_path)
        else:
            input_image = Image.open(image_path)
        
        input_image = input_image.convert("RGB")
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        try:
            width, height = resize_to_target_area(input_image, ratio)
            print(f"ğŸ“ ì¡°ì •ëœ í¬ê¸°: {width}x{height}")
        except ValueError as e:
            print(f"âŒ í¬ê¸° ì¡°ì • ì˜¤ë¥˜: {e}")
            return False
        
        # ì§„í–‰ ìƒí™© ì½œë°± ì„¤ì •
        total_steps = len(model.scheduler.timesteps)
        progress_callback = create_progress_callback(total_steps)
        
        print("ğŸš€ ì´ë¯¸ì§€ ìƒì„± ì‹œì‘...")
        
        # ì´ë¯¸ì§€ ìƒì„±
        output_image = model(
            image=input_image, 
            prompt=prompt, 
            width=width, 
            height=height, 
            guidance_scale=2.5, 
            callback_on_step_end=progress_callback,
            callback_on_step_end_tensor_inputs=["latents"]
        ).images[0]
        
        # ê²°ê³¼ ì €ì¥
        output_image.save(output_path)
        print(f"âœ… ìƒì„± ì™„ë£Œ! ê²°ê³¼ ì´ë¯¸ì§€: {output_path}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜ - CLI ì¸í„°í˜ì´ìŠ¤ ì œê³µ"""
    parser = argparse.ArgumentParser(
        description="Flux Kontext ë¡œì»¬ í…ŒìŠ¤íŠ¸ ë„êµ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python local_test.py image.jpg "make it a watercolor painting" "1:1"
  python local_test.py image.png "add snow" "16:9" --output result.png
        """
    )
    
    parser.add_argument("image", help="ì…ë ¥ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("prompt", help="ì´ë¯¸ì§€ ë³€í™˜ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸")
    parser.add_argument("ratio", help="ì¶œë ¥ ì´ë¯¸ì§€ ë¹„ìœ¨ (ì˜ˆ: 1:1, 16:9, original)")
    parser.add_argument("--output", "-o", default="output.png", help="ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: output.png)")
    
    args = parser.parse_args()
    
    # ì…ë ¥ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(args.image):
        print(f"âŒ ì…ë ¥ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.image}")
        sys.exit(1)
    
    # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    if not torch.cuda.is_available():
        print("âŒ CUDAê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. GPUê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        sys.exit(1)
    
    print("ğŸ¨ Flux Kontext ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤í–‰
    success = process_image(args.image, args.prompt, args.ratio, args.output)
    
    if success:
        print("=" * 50)
        print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    else:
        print("=" * 50)
        print("ğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
        sys.exit(1)

if __name__ == "__main__":
    main() 